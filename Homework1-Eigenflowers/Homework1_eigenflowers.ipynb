{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c55158b",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 1: Eigenflowers (PCA on Images)\n",
    "\n",
    "This notebook walks through an **end-to-end PCA pipeline** on a non-face image dataset (e.g., **Oxford 102 Flowers**).  \n",
    "You will:\n",
    "- Preprocess images (grayscale, resize, flatten)\n",
    "- Build the data matrix `A` (pixels × samples)\n",
    "- Compute PCA via **dual trick** (`L = AᵀA / M`) **or** via **thin SVD**\n",
    "- Visualize the **mean image** and **top eigenimages** (\"eigenflowers\")\n",
    "- Reconstruct images using the top-k components and evaluate error\n",
    "\n",
    "> **For homework 1:** This notebook is commented and includes **TODO** markers.  \n",
    "> Please add your implementation where the **TODO** markers are, including code and Markdown cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a3abb",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Environment & Imports\n",
    "\n",
    "We will use the standard scientific Python packages (`numpy`, `PIL`, `matplotlib`) along with `hashlib`.   \n",
    "Note that each student should have their own unique seed for repeatability.   \n",
    "Make sure your kernel uses Python ≥ 3.8.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97932b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a fixed random seed (given for each student) for reproducibility\n",
    "# **TODO** set your own fixed token with the ***last 4 digits of your UB person number***\n",
    "# Reproducibility via TOKEN\n",
    "TOKEN = \"1234\"  # unique token per student\n",
    "SEED = int(hashlib.sha256(TOKEN.encode()).hexdigest(), 16) % (10**6)\n",
    "print(\"SEED:\", SEED)\n",
    "\n",
    "# Matplotlib defaults (no specific colors)\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f3aa3",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Point to your dataset\n",
    "\n",
    "- Download and extract **Flowers dataset** (from the given image folder) locally.\n",
    "- Set `DATA_DIR` to the folder containing the training images.\n",
    "- Choose a target size (e.g., **64×64**) and an optional cap on images for quick experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ecc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === YOUR INPUTS ===\n",
    "DATA_DIR = \"./dataset/train\"   # <-- TODO: set this to your local training data path\n",
    "OUTPUT_SIZE = (64, 64)         # TODO: you can try (32, 32) for speed\n",
    "MAX_IMAGES = 100               # TODO: set an int (e.g., 10) to cap for quick tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61d551",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Preprocessing helpers\n",
    "\n",
    "We have small utilities for you to:\n",
    "- Walk the dataset directory\n",
    "- Convert to **grayscale**\n",
    "- **Resize** to the same size\n",
    "- **Flatten** to vectors and **normalize** to `[0,1]`\n",
    "- Stack as columns into the data matrix **A** of shape `(pixels, M)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess(data_dir, size=(64, 64), max_images=None):\n",
    "    '''\n",
    "    Load images recursively from 'data_dir'.\n",
    "    Convert to grayscale, resize to 'size', flatten, normalize to [0,1].\n",
    "    Returns:\n",
    "      A: np.ndarray shape (pixels, M)  -- data matrix (columns are images)\n",
    "      paths: list[str]                 -- list of file paths used (length M)\n",
    "    '''\n",
    "    vectors = []\n",
    "    paths = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')):\n",
    "                path = os.path.join(root, fn)\n",
    "                try:\n",
    "                    img = Image.open(path).convert('L').resize(size)  # grayscale + resize\n",
    "                    vec = np.asarray(img, dtype=np.float32).flatten() / 255.0\n",
    "                    vectors.append(vec)\n",
    "                    paths.append(path)\n",
    "                    if max_images is not None and len(vectors) >= max_images:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"[warn] Skipping {path}: {e}\")\n",
    "        if max_images is not None and len(vectors) >= max_images:\n",
    "            break\n",
    "\n",
    "    if not vectors:\n",
    "        raise RuntimeError(\"No images found. Check your DATA_DIR and file extensions.\")\n",
    "\n",
    "    A = np.column_stack(vectors)  # shape: (pixels, M)\n",
    "    return A, paths\n",
    "\n",
    "# Quick test on function signature (no execution yet).\n",
    "print(\"Helper 'load_and_preprocess' defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d66be0",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Load & preprocess images\n",
    "\n",
    "You may want to use only a small number of images and make them small (32x32) while coding and debugging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Uncomment to run when DATA_DIR is set correctly.\n",
    "# A, paths = load_and_preprocess(DATA_DIR, size=OUTPUT_SIZE, max_images=MAX_IMAGES)\n",
    "# print(\"A.shape (pixels x M):\", A.shape)\n",
    "# print(\"Example paths (first 3):\", paths[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5586a6f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) TODO: Mean image & centering\n",
    "\n",
    "PCA expects **mean-centered** data.  \n",
    "- Compute the **mean image** across columns of `A`  \n",
    "- Subtract it from each column to get `A_centered`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Compute the mean image and obtain `A_centered` from the `A` built in the cell above\n",
    "# Then plot your mean image to ensure it looks like a flower... somewhat...\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f2dd8",
   "metadata": {},
   "source": [
    "## 5) TODO: Implement PCA (Method 1): Thin SVD\n",
    "\n",
    "Compute SVD of `A_centered` directly: \n",
    "You can use the `SVD` function from the `linalg` library in numpy\n",
    "> $A_{\\text{centered}} = U \\Sigma V^\\top$\n",
    "\n",
    "- Covariance eigenvalues: $\\lambda_i = \\frac{1}{M}\\sigma_i^2$  \n",
    "- Eigenimages (eigenvectors) are the columns of $U$\n",
    "\n",
    "> **This metod is often numerically preferred as it is more stable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96464158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca_svd(A_centered, num_components=None):\n",
    "    '''\n",
    "    PCA via thin SVD.\n",
    "    Returns:\n",
    "      U_k: eigenimages (pixels x k), orthonormal columns\n",
    "      eigvals_k: covariance eigenvalues (length k), sorted desc\n",
    "    '''\n",
    "    #TODO - enter your code here...\n",
    "    \n",
    "    return U, eigvals\n",
    "\n",
    "print(\"Helper 'pca_svd' defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac48641",
   "metadata": {},
   "source": [
    "\n",
    "## 6) TODO: PCA (Method 2a): Dual trick\n",
    "\n",
    "Compute eigenpairs of the small **sample–sample** $L$ matrix given $A_{\\text{centered}}$:\n",
    "\n",
    "$L = \\frac{1}{M} A^\\top A \\in \\mathcal{R}^{M \\times M}$,\n",
    "\n",
    "- Solve $L v_i = \\lambda_i v_i$; You can use the prebuilt linear algebra $\\texttt{eigvals, V = np.linalg.eigh}$ function call\n",
    "- This will return the eigen values and vectors in $\\textbf{ascending}$ order; you want to reverse this order\n",
    "- Now map this back into the feature space: $u_i = A_{\\text{centered}}\\; v_i$\n",
    "- Normalize each $u_i$ to unit length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pca_dual(A_centered, num_components=None):\n",
    "    '''\n",
    "    PCA via dual trick: eigendecompose L = (A^T A)/M, then map back to feature space.\n",
    "    Returns:\n",
    "      U: eigenimages as columns (pixels x k), unit-norm\n",
    "      eigvals: covariance eigenvalues (length k), sorted desc\n",
    "    '''\n",
    "    #TODO - enter your code here...\n",
    "    \n",
    "    return U, eigvals\n",
    "\n",
    "print(\"Helper 'pca_dual' defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8560268-70b1-4233-a9d0-42fd12e63e01",
   "metadata": {},
   "source": [
    "## 7) TODO: PCA (Method 2b): Dual trick + Eigendecomposition using the Power Method\n",
    "\n",
    "Again we want to compute eigenpairs of the $L$ matrix, but this time we will use the **power method**:\n",
    "\n",
    "- We again want to solve $L v_i = \\lambda_i v_i$\n",
    "- We will implement our own version of the power method\n",
    ">   We will write 2 auxilliary functions to aid with this\n",
    "- Like before, the power method will return the eigen values and vectors, but in descending order\n",
    "- Now map this back into the feature space: $u_i = A_{\\text{centered}}\\; v_i$\n",
    "- Normalize each $u_i$ to unit length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf65b8c-f4a2-4583-aa7c-0d899b9e1880",
   "metadata": {},
   "source": [
    "### Aux 1) TODO: The Power Method for the most dominant eigenpair (single)   \n",
    "$\\textbf{GOAL:}$ Approximate the dominant eigenvalue $\\lambda_{\\max}$ and corresponding eigenvector $v_{\\max}$ of a matrix $L \\in \\mathbb{R}^{m \\times m}$.\n",
    "\n",
    "PSEUDOCODE FOR POWER METHOD:\n",
    "1. Create a random vector $x_0$ of length $\\texttt{L.shape[0]}$  \n",
    "   - Normalize the vector via $\\frac{x_0}{\\|x_0\\|}$  \n",
    "   - Set $\\lambda_0 = 0.0$ <br>\n",
    "\n",
    "2. For $k = 1, 2, \\dots, \\texttt{num\\_iter}$\n",
    "    - Multiply: $y_k = L x_{k-1}$ \n",
    "    - Normalize: $x_k = \\tfrac{y_k}{\\|y_k\\|}$\n",
    "    - Rayleigh quotient: $\\lambda_k = x_k^\\top L x_k$\n",
    "    - if $|\\lambda_k - \\lambda_{k-1}| \\le \\epsilon$; BREAK   \n",
    "\n",
    "3. Output $(\\lambda_k, x_k)$ as approximation of the dominant eigenpair.\n",
    "\n",
    "$\\textbf{Note:}$ these are all matrix multiplications - use the operator \"@\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1ed4b-2044-4b0a-a3e8-89bb48a047b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method_sym(L, num_iters=200, tol=1e-12, x0=None):\n",
    "   '''\n",
    "    power_method_sym takes a symmetrical matrix L, the number of iterations and a tolerance value\n",
    "    Returns:\n",
    "      lam: the most domainant eigenvalue of L\n",
    "      x: the correspondng eigenvector\n",
    "    '''\n",
    "    #TODO - enter your code here...    \n",
    "    \n",
    "    return lam, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2ab0f",
   "metadata": {},
   "source": [
    "### Aux 2) TODO: The Power Method to compute the top-k eigenpairs of L (symmetrical)\n",
    "\n",
    "$k = \\min(k, m)$; where $m$ is $\\texttt{L.shape[0]}$  \n",
    "\n",
    "For $i = 1, 2, \\dots, k$   \n",
    "   - call $\\lambda_k, v_k =$ power_method_sym$(L)$\n",
    "   - next perform a $\\textbf{rank-1 deflation}$ of $L$:\n",
    "      - set $L \\leftarrow L - \\lambda_k v_k v_k^\\top$\n",
    "      - repeat the power method on deflations of $L$ to get the remaining eigenpairs in a descending order of $\\lambda$'s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5db75-e727-486b-929d-4927f4b86340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method_sym_allk(L, k=None, num_iters=200, tol=1e-8, sort_by_abs=True):\n",
    "    \"\"\"\n",
    "    Compute the top-k eigenpairs of a symmetric matrix L using power iteration with deflation.\n",
    "    \"\"\"\n",
    "    #TODO - enter your code here...\n",
    "    \n",
    "    return lambdas, V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b29c8-c6d8-4807-b8c8-ce4a6ebd57dd",
   "metadata": {},
   "source": [
    "### TODO: Now implement pca_dualpower \n",
    "\n",
    "Use the the same signature as the other PCA calls; use your auxilliary methods and have the same return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d2536-7663-45cd-8fe7-4b210232fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_dualpower(A_centered, num_components=None):\n",
    "    '''\n",
    "    PCA via dual trick: using your own handwritten Power Method\n",
    "    Returns:\n",
    "      U: eigenimages as columns (pixels x k), unit-norm\n",
    "      eigvals: covariance eigenvalues (length k), sorted desc\n",
    "    '''\n",
    "    #TODO - enter your code here...\n",
    "      \n",
    "    return U, eigvals\n",
    "\n",
    "print(\"Helper 'pca_dualpower' defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a988cb-4111-4f0e-ad5d-e28a68eb593d",
   "metadata": {},
   "source": [
    "### 8) TODO: Compute your eigenflowers using each of the 3 PCA methods (1:thin SVD, 2:dual method, 3:dual with power method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7eff8f-a709-455d-90db-ab762fcfbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Uncomment and run after you have defined the processes above\n",
    "#U1, eigvals1 = pca_svd(A_centered, num_components=None)\n",
    "# print(\"U1.shape (pixels x k):\", U1.shape)\n",
    "# print(\"eigvals1.shape:\", eigvals1.shape)\n",
    "\n",
    "#U2, eigvals2 = pca_dual(A_centered, num_components=None)\n",
    "#print(\"U2.shape (pixels x k):\", U2.shape)\n",
    "#print(\"eigvals2.shape:\", eigvals2.shape)\n",
    "\n",
    "#U3, eigvals3 = pca_dualpower(A_centered, num_components=None)\n",
    "#print(\"U3.shape (pixels x k):\", U3.shape)\n",
    "#print(\"eigvals3.shape:\", eigvals3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ca4fe",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Visualize the top eigenflowers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12980376",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_eigenimages(U, size, k=6, title_prefix=\"Eigenimage\"):\n",
    "    k = min(k, U.shape[1])\n",
    "    if k <= 0:\n",
    "        print(\"[warn] No eigenimages to display.\")\n",
    "        return\n",
    "    fig, axes = plt.subplots(1, k, figsize=(2.2*k, 2.8))\n",
    "    if k == 1:\n",
    "        axes = [axes]\n",
    "    for i in range(k):\n",
    "        axes[i].imshow(U[:, i].reshape(size[::-1]), cmap=\"gray\")\n",
    "        axes[i].set_title(f\"{title_prefix} {i+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run after U1, U2, U3 are available\n",
    "show_eigenimages(U3, OUTPUT_SIZE, k=6, title_prefix=\"Eigenflower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0882f-45d3-49dc-a5a6-6228670f3fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "864d5ddb",
   "metadata": {},
   "source": [
    "\n",
    "## 10) TODO: Reconstruction with top-k components\n",
    "\n",
    "Pick one image, project onto top-k eigenimages, and reconstruct.  \n",
    "Display your reconstructions  \n",
    "Observe how reconstruction improves as k increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb642e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_with_k(U, mean_image, x_centered, k):\n",
    "    '''\n",
    "        reconstruct_with_k should return a vector of the reconstructed input x_centered\n",
    "    '''\n",
    "    #TODO - enter your code here...\n",
    "    \n",
    "    return recon_x\n",
    "\n",
    "#choose an image index and k (components) list\n",
    "j = 11\n",
    "ks = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "\n",
    "\n",
    "#Load the test images\n",
    "B, _ = load_and_preprocess(TEST_DIR, size=OUTPUT_SIZE, max_images=MAX_IMAGES)\n",
    "B_centered = B - mean_image[:, None] # remeber the mean image must be from A\n",
    "\n",
    "# TODO: Uncomment and run on a training image in A, after it is centered; A_centered, U, and mean_image exist\n",
    "#orig = A[:, j]\n",
    "#x = A_centered[:, j]\n",
    "#then run on the test data\n",
    "#orig = B[:, j]\n",
    "#x = B_centered[:, j]\n",
    "# \n",
    "\n",
    "recons_x = []\n",
    "mses = []\n",
    "for k in ks:\n",
    "    r = reconstruct_with_k(U3, mean_image, x, k)\n",
    "    recons_x.append(r)\n",
    "    mses.append(float(np.mean((orig - r)**2)))\n",
    "\n",
    "# # Plot original + reconstructions\n",
    "cols = len(ks) + 1\n",
    "plt.figure(figsize=(2.2*cols, 2.8))\n",
    "ax = plt.subplot(1, cols, 1)\n",
    "ax.imshow(orig.reshape(OUTPUT_SIZE[::-1]), cmap=\"gray\")\n",
    "ax.set_title(\"Original\")\n",
    "ax.axis(\"off\")\n",
    "for i, (k, r, mse) in enumerate(zip(ks, recons_x, mses), start=2):\n",
    "    ax = plt.subplot(1, cols, i)\n",
    "    ax.imshow(r.reshape(OUTPUT_SIZE[::-1]), cmap=\"gray\")\n",
    "    ax.set_title(f\"k={k}\\nMSE={mse:.4f}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# # Error curve\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(ks, mses, marker=\"o\")\n",
    "plt.xlabel(\"Number of components (k)\")\n",
    "plt.ylabel(\"Reconstruction MSE\")\n",
    "plt.title(\"Reconstruction error vs k\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94fce45",
   "metadata": {},
   "source": [
    "\n",
    "## 11) TODO: Explained variance; plot the cummulative explained variance   \n",
    "\n",
    "Plot how much variation is captured by the first k components.   \n",
    "\n",
    "$EVR_k = \\frac{\\lambda_k}{\\sum_{i=1}^p \\lambda_i}$\n",
    "\n",
    "Cummulative $EVR_m = \\frac{\\sum_{k=1}^m \\lambda_k}{\\sum_{i=1}^p \\lambda_i}$\n",
    "\n",
    "Plot $EVR_m$ at every $m$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ad21e-720c-4a24-8075-f26a68302a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#TODO - enter your code here to solve for cummu, the cummlative EVR\n",
    "\n",
    "#plot cummu\n",
    "plt.figure(figsize=(6,3.5))\n",
    "plt.plot(np.arange(1, len(cummu)+1), cummu, marker='o')\n",
    "plt.xlabel(\"Number of components (k)\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"Explained variance vs components\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a8bd9",
   "metadata": {},
   "source": [
    "\n",
    "## 12) TODO: Feature Mapping\n",
    "- Explain how this approach can be used for feature extraction - you can explain that here...\n",
    "\n",
    "- What exactly are the features and how do we obtain them here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81984393-0e6e-4f9d-b20b-31fb498cc308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
